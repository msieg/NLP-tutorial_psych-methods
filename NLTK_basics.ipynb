{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#CMU pronunciation (phoneme) dictionary\n",
    "import cmudict\n",
    "\n",
    "#Natural Language Toolkit\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmas = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word tokenization from raw text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='Good afternoon everyone, happy halloween!'\n",
    "tokens=word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech tagging tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part-of-speech tag\n",
    "tagged=pos_tag(tokens)\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context-dependent POS tagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Jump\" as a VERB\n",
    "text='Matt can jump really high.'\n",
    "tokens=word_tokenize(text)\n",
    "tagged=pos_tag(tokens)\n",
    "print(tagged[tokens.index('jump')])\n",
    "\n",
    "#\"Jump\" as a NOUN\n",
    "text='That was a high jump.'\n",
    "tokens=word_tokenize(text)\n",
    "tagged=pos_tag(tokens)\n",
    "print(tagged[tokens.index('jump')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word lemmatization by syntactic category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS keys\n",
    "#Noun:      'n'\n",
    "#Adjective: 'a'\n",
    "#Verb:      'v'\n",
    "\n",
    "\n",
    "print(lemmas.lemmatize('biggest','a'))\n",
    "\n",
    "print(lemmas.lemmatize('giraffes','n'))\n",
    "\n",
    "print(lemmas.lemmatize('fighting','v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical frequencies with downloadable SUBTLEX database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read excel file\n",
    "subtlex = pd.read_excel('SUBTLEX.xlsx')\n",
    "\n",
    "#get wordlist column\n",
    "subtlex_wordlist=list(subtlex['Word'])\n",
    "\n",
    "#get Log10 word frequency column\n",
    "freqs=np.array(subtlex['Lg10WF'])\n",
    "\n",
    "#set word frequency dict\n",
    "word_freqs=dict(zip(subtlex_wordlist,freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_freqs['the'])\n",
    "print(word_freqs['unscrupulous'])\n",
    "print(word_freqs['politician'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get phonetic information with importable CMU phoneme dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get phoneme dictionary\n",
    "phonemes=cmudict.dict()\n",
    "\n",
    "#get phonemes\n",
    "word='halloween'\n",
    "phons=phonemes[word][0]\n",
    "print(phons)\n",
    "\n",
    "#count syllables\n",
    "syl_phons=[ph for ph in phons if any(char.isdigit() for char in ph)]\n",
    "num_syls=len(syl_phons)\n",
    "print(num_syls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple rhyme finder with part-of-speech, plurality, syllable and lexical frequency constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TARGET CRITERIA\n",
    "#--Singular noun\n",
    "#--Syllables ≥ 2\n",
    "#--Lexical frequency > 2.0\n",
    "\n",
    "#set target word\n",
    "word1='moon'\n",
    "\n",
    "#get target phonemes\n",
    "phon1=phonemes[word1][0]\n",
    "\n",
    "#strip numerals from phonemes\n",
    "phon1=[[''.join([c for c in ph if not c.isdigit()])] for ph in phon1]\n",
    "\n",
    "#loop through phoneme dictionary until rhyme is found\n",
    "for word2 in phonemes:\n",
    "    \n",
    "    #continue loop if not noun\n",
    "    if 'NN' not in pos_tag([word2])[0][1]:\n",
    "        continue\n",
    "        \n",
    "    #continue loop if not a singular noun\n",
    "    if word2 != lemmas.lemmatize(word2,'n'):\n",
    "        continue\n",
    "\n",
    "    #continue loop if word has frequency < 2.0\n",
    "    if word2 not in word_freqs or word_freqs[word2] < 2.0:\n",
    "        continue\n",
    "        \n",
    "    #get word2 phonemes\n",
    "    phon2=phonemes[word2][0]\n",
    "    \n",
    "    #count syllables\n",
    "    syl_phons=[ph for ph in phon2 if any(char.isdigit() for char in ph)]\n",
    "    num_syls=len(syl_phons)\n",
    "    \n",
    "    #continue if word has less than 2 syllables\n",
    "    if num_syls < 2:\n",
    "        continue\n",
    "        \n",
    "    #strip numerals from phonemes\n",
    "    phon2=[[''.join([c for c in ph if not c.isdigit()])] for ph in phon2]\n",
    "    \n",
    "    #check if last two phonemes match\n",
    "    if phon2[-2]==phon1[-2] and phon2[-1]==phon1[-1]:  \n",
    "        \n",
    "        print(word2)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's wrong with rhyme finder output? We can get more accurate part-of-speech info from SUBLTEX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all possible part-of-speech\n",
    "all_POS=np.array(subtlex['All_PoS_SUBTLEX'])\n",
    "\n",
    "all_POS_freqs=np.array(subtlex['All_freqs_SUBTLEX'])\n",
    "\n",
    "pos_freq_list=[]\n",
    "for pos,pos_freqs in zip(all_POS,all_POS_freqs):\n",
    "    \n",
    "    #if word has multiple possible parts of speech\n",
    "    if '.' in str(pos_freqs):\n",
    "        \n",
    "        #split lists into items\n",
    "        pos=pos.split('.')\n",
    "        pos_freqs=pos_freqs.split('.')\n",
    "        \n",
    "        #change freqs from string to float\n",
    "        pos_freqs=[float(pf) for pf in pos_freqs]\n",
    "        \n",
    "        #normalize pos frequency proportions\n",
    "        pos_freqs=[pf/np.sum(pos_freqs) for pf in pos_freqs]\n",
    "        \n",
    "        #add to list\n",
    "        word_pos_freqs=[[p,f] for p,f, in zip(pos,pos_freqs)]\n",
    "    \n",
    "    #if word has 1 possible part of speech, set proportion to 100\n",
    "    else:\n",
    "        word_pos_freqs=[[pos,1]]\n",
    "        \n",
    "    \n",
    "    pos_freq_list.append(word_pos_freqs)\n",
    "\n",
    "#set word part-of-speech dict\n",
    "word_POS_freqs=dict(zip(subtlex_wordlist,pos_freq_list))\n",
    "\n",
    "\n",
    "print(word_POS_freqs['jump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the rhyme finder again, targeting words that are nouns > 50% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TARGET CRITERIA\n",
    "#--Noun > 50% of occurrences\n",
    "#--Singular noun\n",
    "#--Syllables ≥ 2\n",
    "#--Lexical frequency > 2.0\n",
    "\n",
    "#set target word\n",
    "word1='moon'\n",
    "\n",
    "#get target phonemes\n",
    "phon1=phonemes[word1][0]\n",
    "\n",
    "#strip numerals from phonemes\n",
    "phon1=[[''.join([c for c in ph if not c.isdigit()])] for ph in phon1]\n",
    "\n",
    "#loop through phoneme dictionary until rhyme is found\n",
    "for word2 in phonemes:\n",
    "    \n",
    "    #continue loop if not noun\n",
    "    #if 'NN' not in pos_tag([word2])[0][1]:\n",
    "        #continue\n",
    "    if word2 not in word_POS_freqs:\n",
    "        continue\n",
    "    else:\n",
    "        pos_freqs=word_POS_freqs[word2]\n",
    "        \n",
    "        pf_pos=[pf[0] for pf in pos_freqs]\n",
    "        pf_freq=[pf[1] for pf in pos_freqs]\n",
    "        \n",
    "        if 'Noun' not in pf_pos or pf_freq[pf_pos.index('Noun')] < 0.50:\n",
    "            continue\n",
    "\n",
    "    #continue loop if not a singular noun\n",
    "    if word2 != lemmas.lemmatize(word2,'n'):\n",
    "        continue\n",
    "\n",
    "    #continue loop if word has frequency < 2.0\n",
    "    if word2 not in word_freqs or word_freqs[word2] < 2.0:\n",
    "        continue\n",
    "        \n",
    "    #get word2 phonemes\n",
    "    phon2=phonemes[word2][0]\n",
    "    \n",
    "    #count syllables\n",
    "    syl_phons=[ph for ph in phon2 if any(char.isdigit() for char in ph)]\n",
    "    num_syls=len(syl_phons)\n",
    "    \n",
    "    #continue if word has less than 2 syllables\n",
    "    if num_syls < 2:\n",
    "        continue\n",
    "    \n",
    "    #strip numerals from phonemes\n",
    "    phon2=[[''.join([c for c in ph if not c.isdigit()])] for ph in phon2]\n",
    "    \n",
    "    #check if last two phonemes match\n",
    "    if phon2[-2]==phon1[-2] and phon2[-1]==phon1[-1]:  \n",
    "        \n",
    "        print(word2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
